[
  {
    "objectID": "week1.html#week-1-introduction-to-remote-sensing-and-practical-application",
    "href": "week1.html#week-1-introduction-to-remote-sensing-and-practical-application",
    "title": "2  Week1",
    "section": "2.1 Week 1: Introduction to Remote Sensing and Practical Application",
    "text": "2.1 Week 1: Introduction to Remote Sensing and Practical Application\n\n2.1.1 Summary:\nThis week’s session offered a comprehensive introduction to remote sensing, emphasizing its pivotal role in urban and environmental studies. The lecture detailed various technologies, particularly the distinction between passive and active sensors, and their interaction with electromagnetic waves. In the practical session, we applied these concepts using Sentinel and Landsat data, focusing on York’ s urban landscape. It was a blend of theoretical understanding and practical data analysis. This is a mind map.\n\nknitr::include_graphics(\"figures/week1-mindmap.png\")\n\n\n\n\n\n\n2.1.2 Applications:\nRemote sensing technology is widely used in many fields, such as:\n1. Environmental monitoring and protection: Remote sensing is used to monitor environmental problems such as deforestation, water pollution, and desertification.\n2. Agriculture: Crop health monitoring, land use analysis, yield estimation.\n3. Urban planning and management: urban expansion analysis, transportation planning, infrastructure development.\n4. Disaster management: assessment and response to natural disasters such as floods, earthquakes, and fires.\n5. Climate change research: climate model analysis, global temperature change monitoring, and polar ice cap melting.\n6. National defense and security: border surveillance, military reconnaissance.\n7. Geological research: mineral and resource detection, geological structure analysis.\n8. Oceanography: Marine pollution monitoring, marine ecosystem research.\nI was intrigued by how remote sensing is applied in real-world scenarios, particularly in urban planning and environmental monitoring. The practical session’s data analysis highlighted this application vividly. It allowed me to see firsthand how remote sensing data could be used to observe and assess urban expansion and land use changes. I am also interested in the application of remote sensing in disaster management. One study shows that Remote sensing technology is extensively utilized in defining surface water bodies, estimating meteorological variables like temperature and precipitation, assessing hydrological states such as soil moisture and surface characteristics, and calculating fluxes including evapotranspiration. With the advent of high-resolution satellite data, near-real-time monitoring of floods, droughts, and irrigation management has become increasingly feasible. This advancement enables more efficient and accurate environmental monitoring and resource management (D. and T. V., 2013). Additionally, in Eguchi et al. (2008) studied the application of remote sensing to the magnitude 6.7 earthquake that occurred in Los Angeles on January 17, 1994, the example of bridge collapse could be used for model calibration and validation. They show that remote sensing data can provide a quick and low-risk overview over an extended geographical area, and therefore assess building damage with remote sensing data having significant advantages over ground surveys.\nBoth studies focus on the application of remote sensing technology, but they each focus on different fields. The first article focuses on the application of remote sensing technology in water resources management, including water body mapping, hydrometeorological state variable estimation, and water resources management. In contrast, the second article focuses on the role of remote sensing in the assessment and response to hazards such as earthquakes and tsunamis. Both articles are similar in that they both demonstrate how remote sensing technology can provide critical spatial and temporal data to support more effective monitoring and management. However, their focus areas and specific application scenarios are different, reflecting the broad application potential of remote sensing technology.\n\n\n2.1.3 Reflection:\nFor me, the transition from theoretical concepts to practical applications was particularly enlightening. Practical analysis of satellite data makes abstract concepts more concrete and relevant. It highlights the importance of remote sensing in contemporary urban and environmental challenges, especially in the context of rapid urbanization and climate change. After studying the practical part, I found that directly using tools and data such as SNAP and R to process satellite images was a highlight. Experience analyzing data from different satellites highlights the complexity and precision of remote sensing. This practical insight not only enhanced my understanding of the theoretical aspects but also sparked a stronger interest in the potential applications of this technology in various fields. This week is an enriching start to the course, laying a solid foundation in remote sensing theory and practice. The combination of lectures and practical applications helped deepen my understanding and knowledge of the field."
  },
  {
    "objectID": "week2.html#xaringan-presentation-infrared-sensor",
    "href": "week2.html#xaringan-presentation-infrared-sensor",
    "title": "3  Week2",
    "section": "3.1 Xaringan Presentation-Infrared Sensor",
    "text": "3.1 Xaringan Presentation-Infrared Sensor\nHere is a short presentation discussing the infrared sensor."
  },
  {
    "objectID": "week3.html#week-3-corrections",
    "href": "week3.html#week-3-corrections",
    "title": "4  Week3",
    "section": "4.1 Week 3: Corrections",
    "text": "4.1 Week 3: Corrections\n\n4.1.1 Summary:\nThis week’s lecture details the processing and application of remote sensing data. The main parts include: Historical review: Involving the Landsat program and Virginia Norwood’s contributions to remote sensing technology. Remote sensing data correction: Introduces the concepts and methods of geometric correction, atmospheric correction and radiometric correction. Data merging and enhancement: including image stitching, image enhancement and other technologies, emphasizing the importance of these technologies in urban environments. Application Case: Describes the application of remote sensing technology in urban environments, exploring how increasing data complexity or creating new data sets can help achieve specific goals. This is a mind map.\n\nknitr::include_graphics(\"figures/week2-mindmap.png\")\n\n\n\n\nThrough this week’s practical content, I learned how to remove the influence of the atmosphere from remote sensing images to obtain more accurate surface information. The document then describes specific techniques such as dark object subtraction (DOS), a method of estimating and correcting atmospheric scattering by subtracting the darkest pixel values from an image. More, I also learned the specific steps and calculation formulas on how to use these technologies to convert received radiation values (such as data captured by remote sensing satellites) into reflectivity. Namely 1. Radiometric calibration: This step converts the raw data captured by the satellite sensor (usually digital image data, that is, DN value) into actual radiance. This requires the use of satellite-specific scaling factors. 2. Atmospheric Correction: Use techniques such as Dark Object Subtraction (DOS) to reduce the effects of atmospheric scattering. This is to remove atmospheric interference from the captured data, resulting in a more accurate representation of actual conditions on the ground. 3. Reflectance conversion: Convert the atmospherically corrected radiance value into reflectance. This typically involves considerations of solar radiation intensity, viewing angle, and other geophysical parameters. This process is critical for analyzing and interpreting remote sensing images, as reflectance more accurately reflects surface properties. Through these technologies and formulas, users can better process and interpret remote sensing data for effective environmental monitoring and analysis.\n\n\n4.1.2 Applications:\nIn the field of remote sensing and image processing, the application of “corrections” is very extensive and important. These correction techniques, such as atmospheric correction (including dark object subtraction DOS), terrain correction, and radiometric correction, are used to improve the quality and accuracy of satellite images. Application areas include: Environmental monitoring: Accurately track forest destruction, droughts, floods, and more. Agriculture: Monitor crop health, assess drought impacts. Urban planning: monitoring of urban expansion and land use changes. Climate change research: looking at glacier retreat, sea level rise, and more. Disaster response: rapid assessment after fire, flood, earthquake.\nSpecifically, I have a strong interest in the application of atmospheric correction to agriculture. A 2010 study by Chrysolakis et al. compared several atmospheric correction methods used in the Crete region, specifically their impact on land cover classification and change detection. They applied four different atmospheric correction methods to a time series of ASTER images and compared the effects of these methods with the spatial distribution of surface reflectance as a baseline. This comparison uses emissivity and brightness temperature data provided by ASTER Advanced Products. The results show that the DP method provides satisfactory results in the visible, near-infrared and shortwave infrared spectral regions and is therefore suitable for local applications related to land cover and vegetation. In agricultural remote sensing applications, the effective implementation of atmospheric correction techniques is critical to improving the accuracy of surface reflectance data in crop-covered areas. A study evaluated the ability of DOS-COST and AR models to obtain surface reflectance from QuickBird imagery of Minnesota farmland, highlighting model performance in different wavebands and under different atmospheric conditions. The results include an in-depth discussion of the accuracy of the model in the visible and near-infrared bands, as well as adjustments made to improve estimates of atmospheric transmittance in the near-infrared (WU, WANG and BAUER, 2005). This exploration of the impact of atmospheric correction on agricultural monitoring accuracy provides a comprehensive case study of the practical applications and challenges of agricultural remote sensing image analysis.\nThe two articles are similar in that they both aim to improve the accuracy of surface reflectance extraction from satellite images, reducing atmospheric effects on remote sensing data through atmospheric correction. However, they differ in the data sources used, the study areas, the atmospheric correction methods examined, and the specific way in which their impact on land cover classification and change detection is assessed. The first research focuses on a comparative study of atmospheric corrections over the Crete region of Greece using ASTER data. It explores the study of the impact of several atmospheric correction methods on land cover classification and change detection, covering creating a spatiotemporal distribution database, applying four atmospheric correction methods, and evaluating the impact of atmospheric correction on land cover classification and change detection. The second paper mainly studies image-based atmospheric correction algorithms, using QuickBird satellite data to obtain the surface reflectance of farmland canopy. It compares algorithms such as DOS (Dark Matter Subtraction Technique), COST (Cosine Approximation Model) and AR (Apparent Reflectance Model) and evaluates the accuracy of these models based on ground measurement data.\n\n\n4.1.3 Reflection:\nAfter delving deeply into this week’s course content on remote sensing data processing and applications, I found that I have a strong interest and curiosity in how to apply this knowledge to a wider field. But again, this is a bit difficult for me. After learning about data correction techniques, I started thinking about how these techniques could be used in current and future research, and how they might open up new avenues of analysis or work. For example, atmospheric correction, terrain correction, and radiometric correction are not only critical for improving the quality of remote sensing images, but also provide us with a means to better understand the Earth system through more accurate data. Mastery of these correction techniques allows me to think about how they can be applied to solve practical problems in areas such as environmental monitoring, agricultural development, and urban planning. In addition, the learning and application of these remote sensing data processing techniques prompted me to think about other potential research areas, such as using remote sensing techniques for climate change research or disaster response. As the impacts of climate change become increasingly apparent, the effective use of remote sensing data to monitor glacier retreat, sea level rise, and extreme climate events has become an important task. This requires not only precise data correction techniques, but also interdisciplinary collaboration and innovative approaches to parse large amounts of data. In the end, I realized that while this week’s course content provided me with valuable knowledge and skills, it was just the beginning. Learning remote sensing techniques and data processing methods opens a way to explore the Earth and our role in it. As technology continues to advance and data sets expand, there will be greater opportunities to explore new questions, discover new insights, and have a profound impact on our world. I look forward to applying this knowledge to my future studies and research, not only to solve existing problems but also to open up new avenues of analysis and work. This week’s learning experience not only strengthened my technical skills, but more importantly, it sparked my interest and curiosity in applying these tools and data to a wider range of disciplines and challenges."
  },
  {
    "objectID": "week4.html#week-4-policy",
    "href": "week4.html#week-4-policy",
    "title": "5  Week4",
    "section": "5.1 Week 4: Policy",
    "text": "5.1 Week 4: Policy\n\n5.1.1 Summary:\nThe city I chose is the capital of Indonesia, Jakarta. Jakarta is one of the most densely populated cities in the world. The city is facing many challenges, including rapid urbanization, traffic congestion, air pollution, land subsidence due to falling water tables (25cm per year), and severe flood risk. These The problem not only threatens the sustainable development of cities, but also affects the quality of life of residents.\nAmong them, the most serious problem is subsidence caused by rising sea levels, Jakarta is located on the northwest coast of Java, Indonesia. Parts of the city are built on swampland. This geological structure itself is relatively prone to subsidence. In addition, rising sea levels caused by global warming have exacerbated Jakarta’s subsidence problem, especially in coastal areas, which face greater risks of flooding. Some human factors also lead to ground subsidence. First, huge amounts of underground water pumping, primarily for residential, commercial and industrial water use, became an uncontrolled activity (Colven, 2020). Second, rapid urban expansion and large-scale construction projects have increased ground pressure, especially in swamps and soft soil. Third, the system has insufficient drainage, such as frequent rainfall that prevents ground moisture from draining away.\nMore details are in the video below.\n\n\nsource: Youtube(https://www.youtube.com/embed/Z9cJQN6lw3w)\nIn order to solve the subsidence problem in Jakarta, the Indonesian government and local agencies are taking a series of measures: Restrict groundwater extraction: Adopt laws and policies to limit illegal groundwater extraction and promote the use of alternative water sources, such as surface water and recycled water. Build seawalls and locks: Build large-scale seawall and lock projects to control seawater intrusion and mitigate the effects of flooding. Improve urban drainage systems: Improve and expand urban drainage systems to increase their ability to handle rainfall and flooding. Sustainable urban planning: Promote green building and sustainable urban planning concepts to reduce negative impacts on the environment and address the challenges posed by land subsidence.\nSome predictions indicate that Jakarta will completely sink by 2050. Therefore, the government and relevant departments should continue to speed up the pace and actively respond. The next section: “Application” will talk about the specific application of remote sensing technology in sea level rise and ground subsidence.\n\n\n5.1.2 Applications:\nIn the case of Indonesia, especially Jakarta, remote sensing technologies (including InSAR and GNSS) are often used to help study land subsidence problems in low-lying coastal areas (Andreas et al., 2020), through geological surveys (such as leveling, global Navigation Satellite System (GNSS) and Synthetic Aperture Radar Interferometry (InSAR)), which can identify annual subsidence rates. The authors analyze time series of remote sensing data such as Google Earth or Landsat image archives, combined with land subsidence measurements and groundwater monitoring point data, as well as the mentioned statistical data to identify land subsidence areas, coastal land subsidence affected areas, potential seawater intrusion and aquifers method of damage.\nRemote sensing technology plays an important role in helping to deal with land subsidence. It can provide effective detection and analysis of all aspects. First, synthetic aperture radar (SAR) technology can provide high-resolution surface deformation images to help identify and monitor ground subsidence areas. Interferometric Synthetic Aperture Radar (InSAR) is a remote sensing technology used to monitor surface deformation. It can accurately detect small changes in the surface such as land subsidence, landslides and post-earthquake deformation. InSAR technology analyzes tiny deformations on the ground through images acquired by synthetic aperture radar (SAR). InSAR data allows for time series analysis, which has become an important tool for detecting, measuring, and analyzing displacements on the Earth’s surface (Osmanoğlu et al., 2016). In addition, SAR measurements include both amplitude and phase observations. Amplitude refers to the intensity of backscattered electromagnetic waves, which is related to the shape, direction and electrical characteristics of the target. The phase reflects the change of the wave, but it is difficult to accurately obtain the total number of distance or wavelength. By comparing the phase changes in the two SAR measurements, we can detect the small changes that occurred between the two imaging times. This method is called InSAR (Osmanoğlu et al., 2016). The following figure illustrates the basic observable phase of a typical InSAR measurement.\n\nknitr::include_graphics(\"figures/w4-InSAR.png\")\n\n\n\n\nfigure1: Schematic explaining repeated pass interferometry (Osmanoğlu et al., 2016)\nIn this study, Osmanoğlu et al. (2016) used InSAR data time series analysis to compare the performance of four different algorithms (PSI, SBAS, SqueeSAR, StaMPS) in dealing with land subsidence monitoring in Mexico City. The study found that despite the high ground subsidence rate in Mexico City, the four algorithms all obtained similar settlement rates and deformation patterns, but the StaMPS method gave a lower settlement rate. In addition, the theory of combining time series analysis with phase unwrapping can provide potential technical and computational advantages for analyzing InSAR observations in three dimensions (two space and one time).\nAccording to Ma et al. (2019) for the study of land subsidence in the Guangdong-Hong Kong-Macao Greater Bay Area (GBA) in China, we can determine that single-sensor synthetic aperture radar (SAR) images have a smaller coverage area and lower resolution, due to Sediments in the GBA are widely distributed, so SAR is not suitable for complete monitoring of the GBA. Therefore, in their study, the authors used the MT-InSAR method, using a combination of Sentinel-1 (S1), COSMO-SkyMed (CSK), and TerraSAR-X (TSX) images to reveal the multiscale subsidence of the GBA. Recognizing the advantages of MT-InSAR, several studies have applied it to monitor subsidence-prone bay/delta regions around the world.\nThe first article mainly discusses the application of time series analysis of InSAR data in monitoring and measuring earth surface deformation. The article discusses the need for phase unwrapping to obtain meaningful results due to the large surface variability, and mentions several different algorithms developed for this purpose. Although these algorithms are based on different models, they can all produce first-order deformation rates and can be compared with each other. The article proposes that no single algorithm can provide optimal results in all situations, as each algorithm has its own unique advantages and disadvantages, and is discussed in the paper through measurements of sinking rates in Mexico City. The second article focuses on the multi-scale subsidence problem in the Guangdong-Hong Kong-Macau Greater Bay Area (GBA) and analyzes the main causes of subsidence in the region. This article uses Sentinel-1 (S1), COSMO-SkyMed (CSK) and TerraSAR-X (TSX) images, and uses a variety of SAR images to reveal the multi-scale subsidence phenomenon in the GBA area. In addition, the article specifically mentions two local subsidence cases and emphasizes that CSK data is superior to S1 data in some aspects, such as point density, height accuracy and fewer false alarms. Finally, the article summarizes the practicality of using multi-sensor SAR images for regional surveys and fine monitoring of local areas.\nIn summary, the second article focuses more on the methods and algorithms of InSAR data analysis, while the third one focuses more on the surface subsidence problem in a specific area (i.e. GBA), and uses multi-sensor SAR images for monitoring. Both articles discuss the application of InSAR technology in ground monitoring, but the focus and geographical scope are different.\n\n\n5.1.3 Reflection:\nStudying policy issues in Jakarta in this module introduced me to the many ways in which remote sensing data can be used to address urban environmental issues such as land subsidence. Exploring remote sensing technologies such as InSAR and GNSS through Jakarta’s land subsidence problem highlights the key role of technological advancement in environmental monitoring and urban planning. Gaining a deeper understanding of how these technologies can provide high-resolution images and data to effectively detect and analyze ground deformation has not only enhanced my understanding of land subsidence monitoring, but also expanded my knowledge of the application of these technologies in a broader context. Through detailed case studies comparing Mexico City and China’s Guangdong-Hong Kong-Macau Greater Bay Area, I learned how different InSAR data analysis algorithms and methods can be leveraged to address specific geographic and situational needs. The importance of choosing appropriate algorithms is a valuable lesson for any policy or environmental analysis. Furthermore, it is predicted that Jakarta may be completely submerged by 2050 if drastic measures are not taken, reminding us of the urgency needed when addressing environmental issues. This prompts us to consider the wider implications of urban policy and planning, the key importance of sustainable practices, and the delicate balance that must be struck between development and conservation.\n\n\n5.1.4 References:\nAndreas, H., Abidin, H.Z., Sarsito, D.A. and Pradipta, D. (2020). Remotes sensing capabilities on land subsidence and coastal water hazard and disaster studies. IOP Conference Series: Earth and Environmental Science, 500(1), p.012036. doi:https://doi.org/10.1088/1755-1315/500/1/012036.\nColven, E. (2020). Subterranean infrastructures in a sinking city: the politics of visibility in Jakarta. Critical Asian Studies, 52(3), pp.311–331. doi:https://doi.org/10.1080/14672715.2020.1793210.\nMa, P., Wang, W., Zhang, B., Wang, J., Shi, G., Huang, G., Chen, F., Jiang, L. and Lin, H. (2019). Remotely sensing large- and small-scale ground subsidence: A case study of the Guangdong–Hong Kong–Macao Greater Bay Area of China. Remote Sensing of Environment, 232, p.111282. doi:https://doi.org/10.1016/j.rse.2019.111282.\nOsmanoğlu, B., Sunar, F., Wdowinski, S. and Cabral-Cano, E. (2016). Time series analysis of InSAR data: Methods and trends. ISPRS Journal of Photogrammetry and Remote Sensing, 115, pp.90–102. doi:https://doi.org/10.1016/j.isprsjprs.2015.10.003."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week6.html#week-6-an-introduction-to-google-earth-engine",
    "href": "week6.html#week-6-an-introduction-to-google-earth-engine",
    "title": "6  Week6",
    "section": "6.1 Week 6: An introduction to Google Earth Engine",
    "text": "6.1 Week 6: An introduction to Google Earth Engine\n\n6.1.1 Summary:\nThis is a mind map of this week’s lecture.\n\nknitr::include_graphics(\"figures/w6-GEE.png\")\n\n\n\n\nThrough this week’s practical content, I initially learned how to use JavaScript to write code in GEE, including the use of some basic programming concepts such as variables, strings, lists, and dictionaries. First, geographical information points were created, Landsat data was imported, and GEE operations such as image clipping and texture measurement were performed. I also learned to process data and how to load, filter and display image datasets, by processing image collections, using equal methods such as straight, mean, etc. to synthesize images. Next, I learned how to use principal component analysis (PCA) to reduce the dimensionality of image data, including how to calculate covariance matrices, eigenvalues, and eigenvectors, and output the results as images. The figure below is a screenshot of my practice following the practical content.\n\nknitr::include_graphics(\"figures/w6_practical.png\")\n\n\n\n\n\n\n6.1.2 Applications:\nGoogle Earth Engine (GEE) is widely used in many fields because of its powerful data analysis capabilities and large geographical information data sets. Some major applications include: environmental monitoring, agriculture, climate change research, land cover mapping, disaster management, etc.\nAmong them, in agriculture, GEE can be used to monitor crops, predict yields, and manage agricultural resources more effectively. It helps assess crop health, soil moisture, and predict pest infestations. Mutanga and Kumar (2019) studied several key applications of GEE in agriculture, including crop yield estimation, crop area mapping, pest and disease vulnerability and suitability assessment. Among them, using Terra MODIS data and Landsat data, GEE was able to estimate the total primary productivity of seven crops in Montana, USA, from 2008 to 2015 at a spatial resolution of 30 meters. High spatial resolution Worldview 2 data were used to map smallholder heterogeneous farmland areas in the African context of Mali. This mapping utilizes set rules to optimize classification accuracy, demonstrating the high processing power of GEE. Moreover, using a combination of 10-day period Sentinel data and 16-day period Landsat TM data, a map of farmland and non-farmland area across the African continent was drawn. And classify the above data using random forest algorithm and recursive hierarchical partitioning to further analyze and understand the data.\nThere is also a study on Canadian cropping intensity (ACI) mapping using Google Earth Engine (GEE). Amani et al. (2020) proposed a cloud computing method using a combination of multi-date Sentinel-1 and Sentinel-2 images acquired in 2018, implemented on the GEE platform, to generate object-based ACI maps. By applying artificial neural networks (ANN), 17 farmland categories in 10 Canadian provinces were delineated. The research results show that the overall classification accuracy is 77%, and the average producer accuracy (PA) and user accuracy (UA) of the cultivated land category are 79% and 77% respectively. It also proves that using the GEE cloud platform and open-access Sentinel-1/-2 satellite images greatly reduces time and economic costs compared to using local computing resources and expensive RADARSAT-2 images, helping to automate future ACI maps. Production.\nThese two studies demonstrate the application of Google Earth Engine (GEE) in the agricultural field, especially the potential in crop monitoring, yield prediction, and resource management. Although their geographical areas of focus and specific applications are different, they collectively reflect GEE’s ability to process large amounts of geospatial data and perform efficient classification and analysis. Both studies used satellite data, including Sentinel-1, Sentinel-2 and Landsat data, for map production and analysis. And both aim to improve agricultural management and monitoring through more precise geospatial data analysis, such as crop yield estimation, farmland classification, etc. However, the first study focused more on the estimation of total primary productivity of crops, mapping of farmland area and classification of small-scale farmland using high-resolution data using methods such as ensemble rules and random forest algorithms. The second study focuses on using artificial neural network (ANN) technology to generate object-based crop intensity (ACI) maps on the GEE platform. Through these studies, we can see the broad applicability and benefits of GEE in agricultural research in different regions around the world. However, the impact of data spatial resolution on precision agricultural monitoring is also an issue worth discussing. For example, using 30-meter resolution Landsat data to estimate total crop primary productivity in Montana may not be as accurate as using higher-resolution data (such as Worldview 2 data) to map small-scale farmland in Mali. This prompts us to weigh the coverage and resolution of the data when selecting data sources to better adapt to specific application needs.\n\n\n6.1.3 Reflection:\nThe Google Earth Engine (GEE) we learned this week is inspiring, and it vividly demonstrates the combination of programming and geospatial analysis. When I first tried programming in GEE using JavaScript, I found it difficult but took it as a challenge. Through these, I realized the importance of independent learning and problem solving. When encountering programming difficulties, although the code in the tutorial is very detailed, when trying to fully understand it, I learned how to search for relevant information, read documents, and ask peers for help. These abilities will be extremely valuable for my future’ s study and work.\n\n\n6.1.4 References:\nAmani, M., Kakooei, M., Moghimi, A., Ghorbanian, A., Ranjgar, B., Mahdavi, S., Davidson, A., Fisette, T., Rollin, P., Brisco, B. and Mohammadzadeh, A. (2020). Application of Google Earth Engine Cloud Computing Platform, Sentinel Imagery, and Neural Networks for Crop Mapping in Canada. Remote Sensing, 12(21), p.3561. doi:https://doi.org/10.3390/rs12213561.\nMutanga, O. and Kumar, L. (2019). Google Earth Engine Applications. Remote Sensing, 11(5), p.591. doi:https://doi.org/10.3390/rs11050591."
  },
  {
    "objectID": "week7.html#week-7-classification-i",
    "href": "week7.html#week-7-classification-i",
    "title": "7  Week7",
    "section": "7.1 Week 7: Classification I",
    "text": "7.1 Week 7: Classification I\n\n7.1.1 Summary:\nThis is a mind map of this week’s lecture.\n\nknitr::include_graphics(\"figures/week7_mindmap.png\")\n\n\n\n\nThis week’s practical involves digital image processing, remote sensing information extraction technologies and methods, such as pattern recognition, supervised classification, unsupervised classification, information extraction using artificial intelligence, etc. It discusses techniques such as support vector machines, random forest classifiers, and remote sensing thematic map accuracy assessment in detail. In addition, the method of using Google Earth Engine for cloud-based remote sensing data processing is also introduced, including the process of data acquisition, vector data processing, and the use of different algorithms for image classification and accuracy evaluation. Through practical cases, I learned how to process remote sensing data, perform land cover classification, and evaluate the accuracy of classification results. Random forest is an ensemble learning method that improves the accuracy and robustness of classification by building multiple decision trees. In remote sensing image processing, random forests can effectively process large amounts of data and provide accurate classification results. I am mainly interested in how to train a random forest classifier on the GEE platform, including selecting training and validation samples, training the classifier using the random forest algorithm, and evaluating the accuracy of the classification results. This process involves segmenting the data set, selecting an appropriate feature set, and using tools such as confusion matrices to verify the classification effect. In addition, the practical also emphasizes how to avoid overfitting (shown in the Figure1 below) when processing remote sensing images and ensure the generalization ability of the model by correctly segmenting the data set.\n\nknitr::include_graphics(\"figures/w7_overfitting.png\")\n\n\n\n\nFigure1 overfitting Source: Seema Singh\n\n\n7.1.2 Applications:\nThis section mainly studies the application of machine learning in the field of remote sensing.\nLary et al. (2016) summarized some ML applications and reviewed the unique techniques of machine learning techniques for dealing with geoscience and remote sensing problems. They used and presented two illustrative examples: one using multivariate nonlinear nonparametric regression, and the other One uses multivariate nonlinear unsupervised classification. They used machine learning to estimate atmospheric aerosol abundance and identify and classify dust sources in remotely sensed images. Multivariate nonlinear and nonparametric machine learning methods can capture the relationship between PM2.5 (fine particles) and AOD (aerosol optical depth), and it is able to handle continuous real variables and categorical variables (flags and masks). In addition, self-organizing maps are used to reduce data dimensionality by using self-organizing neural networks. When the authors identify and classify dust edges in remote sensing images, SOMs achieve dimensionality reduction by producing feature maps that usually have two dimensions. Objectively map similarities in data by grouping similar data items together. SOMs are able to learn how to classify input vectors based on their grouping in the input space, thereby learning to recognize adjacent parts of the input space. This approach allows SOMs to display similarities and reduce dimensionality, and they are able to represent nonlinear functions or maps, a significant improvement over principal component analysis (Lary et al., 2016).\nFor the application of image classification, Yang et al. (2003) studied the application of decision tree technology in image classification using remote sensing data. The study used the classification and regression tree (C&RT) method (Figure 2 shows the overall architecture of the developed C&RT model) to classify plots with different tillage treatments (conventional tillage, reduced tillage or no tillage) and different crops (silage corn or grain corn). Using 71 bands of hyperspectral reflectance ranging from 400 to 950 nanometers as input, the study found that the C&RT model was able to better differentiate between farming practices and residue levels, showing the effectiveness of the decision tree in image processing using hyperspectral reflectance directly as input. Classification potential. Furthermore, decision tree models show better classification performance compared to traditional regression methods. This technology is important for rapidly mapping tillage and residue management practices, thereby aiding in research on the impact of tillage and residue management on soil erosion and other environmental issues. While the study demonstrates the effectiveness of the decision tree technique on a specific data set, it does not explicitly state how the model’s generalization ability is assessed, such as by testing with cross-validation or independent data sets. Additionally, comparing the performance of decision trees and other machine learning methods (such as support vector machines or random forests) on the same task may provide a more comprehensive assessment.\n\nknitr::include_graphics(\"figures/w7_tree.gif\")\n\n\n\n\nFigure2 General structure of a data-mining decision tree. Source: Yang et al. (2003)\nThese two articles focus on different applications of machine learning in the field of remote sensing. The first article explores the application of machine learning, especially multivariate nonlinear and nonparametric machine learning methods, in estimating atmospheric aerosol abundance and identifying dust sources, highlighting its importance in air quality and climate change research. The second article focuses on the application of decision tree technology in image classification, demonstrating the potential of decision trees in hyperspectral image processing and accurate mapping of farming practices by using hyperspectral reflectance data to classify farming treatments and crop species. Overall, both articles demonstrate the power of machine learning techniques in remote sensing data analysis.\n\n\n7.1.3 Reflection:\nLooking back over this week, I recognized the application of machine learning techniques, specifically decision trees and random forest classifiers, in enhancing the analysis and classification of remote sensing images. Cloud-based data processing using Google Earth Engine reveals the complex balance between leveraging sophisticated algorithms to improve accuracy and the need to prevent overfitting to maintain model generalization. This exploration not only broadened my understanding of remote sensing applications but also highlighted the importance of methodical sample selection and algorithm evaluation in generating reliable, actionable insights from large data sets. My interest in the practical applications of these technologies has deepened, and this week’s learning has inspired me to think more deeply about how machine learning can be further integrated into environmental monitoring and analysis.\n\n\n7.1.4 References:\nLary, D.J., Alavi, A.H., Gandomi, A.H. and Walker, A.L. (2016). Machine learning in geosciences and remote sensing. Geoscience Frontiers, [online] 7(1), pp.3–10. doi:https://doi.org/10.1016/j.gsf.2015.07.003.\nSingh, S. (2018). Understanding the Bias-Variance Tradeoff. [online] Medium. Available at: https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229.\nYang, C.-C., Prasher, S.O., Enright, P., Madramootoo, C., Burgess, M., Goel, P.K. and Callum, I. (2003). Application of decision tree technology for image classification using remote sensing data. Agricultural Systems, [online] 76(3), pp.1101–1117. doi:https://doi.org/10.1016/S0308-521X(02)00051-3."
  },
  {
    "objectID": "week8.html#week-8-classification-the-big-questions-and-accuracy",
    "href": "week8.html#week-8-classification-the-big-questions-and-accuracy",
    "title": "8  Week8",
    "section": "8.1 Week 8: Classification The Big Questions and Accuracy",
    "text": "8.1 Week 8: Classification The Big Questions and Accuracy\n\n8.1.1 Summary:\nThis is a mind map of this week’s lecture.\n\nknitr::include_graphics(\"figures/week8_mindmap.png\")\n\n\n\n\nFor the data and methods of this week’s content, I learned about ground cover classification, utilizing pre-classified data and dynamic world data, and improving classification accuracy through advanced methods such as convolutional neural networks (CNN). In addition, sub-pixel analysis improves the fine-grainedness of classification by calculating the proportion of different ground cover types within a pixel. We also learned accuracy evaluation, using indicators such as confusion matrix, producer accuracy, user accuracy, and overall accuracy to evaluate classification results. It also discusses the use and controversy of Kappa coefficient, as well as the application of F1 score and ROC curve in accuracy evaluation. But at the same time, these methods also have limitations. Although machine learning methods are powerful, they rely on large amounts of high-quality training data, and model decisions are sometimes difficult to interpret. Accuracy assessment methods (such as Kappa coefficient) are controversial and may not be appropriate in all situations. With the continuous advancement of deep learning and other advanced machine learning technologies, it is expected that the accuracy and efficiency of remote sensing data analysis will be further improved. The development of new accuracy assessment metrics and methods may provide more comprehensive and accurate assessment methods.\nThis week’s practical session mentions a variety of resources and research, including using Google Earth Engine to integrate Sentinel-1, Sentinel-2 and PlanetScope satellite data for object-based mapping of informal settlements, and various projects using cloud services for remote sensing. techniques and strategies. From this I learned 1. Advanced classification methods: How to use advanced classification methods, including sub-pixel classification, linear spectral unmixing and spectral mixing analysis. These methods allow for more precise identification and classification of ground objects, especially in complex urban environments. 2. Change detection: How to perform change detection, which is an important area in remote sensing research, especially in monitoring urbanization processes, environmental changes, etc. 3. How to implement these advanced classification and change detection methods in Google Earth Engine. This includes loading and styling vector data, processing Landsat data, using cloud masking capabilities, and performing object-based classification. The following is a screenshot when I practiced this week’s content in GEE. I encountered a bug that I am trying to solve.\n\nknitr::include_graphics(\"figures/w8_practical.png\")\n\n\n\n\n\n\n8.1.2 Applications:\nOf what I learned this week, I was primarily interested in using remote sensing techniques to analyze land cover changes. Remote sensing technology has become an important tool for detecting land cover changes because it can provide large-scale, multi-temporal surface information. The following are specific methods and their applications.\nGómez, White and Wulder (2016) discuss methods and advances in land cover classification using optical remote sensing time series data. The article first points out that accurate land cover information is very important for scientific monitoring and reporting. Earth observation (EO) data enables consistent and reliable monitoring and mapping of land cover and its changes over large areas. The increase in EO data—particularly from the Landsat archive (soon to include Sentinel-2 data)—as well as improvements in image synthesis methods have now enabled the delivery of annual, seamless surface reflectance products. These data products support the development of annual land cover products that can be guided and constrained by change detection results. In addition, the article also explores new inputs in land cover classification, such as stabilization of land cover transformation and temporal classification, combination of multi-scale and multi-sensor spectral data, multiple temporal spectral variables, and optimized training sample data.\nAnother study introduced a novel subpixel-level change detection method for urban land cover analysis from multi-temporal remote sensing imagery. This method is based on spectral hybrid analysis and decision-level fusion design, aiming to solve the problem of complex and variable land use/cover components within a single pixel due to spatial resolution limitations in medium-resolution remote sensing images for monitoring urban land cover changes. Traditional hard detection methods based on pure pixel assumptions often lead to a high degree of omissions and misjudgment errors by ignoring spectral variations within pixels, thereby reducing the overall accuracy of change detection (DU et al., 2014). To solve this problem, DU et al. (2014) proposed a change detection method based on a nonlinear spectral mixture model. They achieved sub-pixel level change detection by analyzing subtle changes within a single pixel and combining multiple compositional evidences. . This method uses a backpropagation neural network (BPNN) for spectral separation to generate abundance values of different ground components, and then analyzes the abundance values of all ground components and determines detailed change information through decision-level fusion. The figure below is a flow chart of this method. In experiments, this method was applied to multi-temporal Landsat Thematic Mapper and China-Brazil resource satellite remote sensing images for land cover change detection in urban areas.\n\nknitr::include_graphics(\"figures/week8_sub-pixel.png\")\n\n\n\n\nFlowchart of the proposed sub-pixel level change detection approach Source: DU et al. (2014)\nBoth studies above used remote sensing technology to analyze land cover changes. They all highlight the importance of time series data in analyzing land cover changes. Dynamic changes in land cover can be better monitored and understood using multi-temporal data. The first study summarizes various methods and advances in land cover classification using optical remote sensing time series data, emphasizing the application of time series information in land cover classification and monitoring, including the generation of annual land cover products and the use of time series change information for land cover classification. Override mapping strategy. The application of time series data in land cover classification is discussed more broadly, not only in urban areas, but also in various land cover types including forests, farmland, etc., and a series of operational strategies and classification methods for integrating time series data are proposed. The second article focuses on proposing a new sub-pixel level change detection method, which is based on a nonlinear spectral mixture model and decision-level fusion, and can detect subtle land cover changes at the sub-pixel level. The author verified the effectiveness of the proposed method in urban land cover change detection through experiments, focusing on improving the accuracy of change detection in urban areas through sub-pixel change detection technology.\n\n\n8.1.3 Reflection:\nThis week’s study gave me an in-depth understanding of the application of remote sensing technology in the analysis of land cover changes. Through advanced classification methods, change detection technology, and practical operations with Google Earth Engine, I have a more specific understanding of how to use remote sensing data for precise analysis. In particular, I have developed a strong interest in sub-pixel analysis methods because of their ability to reveal more nuanced proportions of land cover types within individual pixels, which is particularly important in complex urban environments. But I know the potential applications of these techniques and methods extend far beyond that. For example, these technologies can be used in various fields such as urban planning, disaster management, and agricultural monitoring. Especially today, when climate change and environmental protection have become the focus of global attention, remote sensing technology provides a powerful tool for monitoring changes in the earth’s surface. At the same time, I also started thinking about how to apply these technologies in future research or projects, how to integrate these technologies into my research field, and how they can help solve broader social, economic and environmental problems. In addition, in my previous studies, I also learned about accuracy tables. Through this week’s study, I understood how it is applied in the field of remote sensing, which deepened my understanding of confusion matrices.\n\n\n8.1.4 References:\nDU, P., LIU, S., LIU, P., TAN, K. and CHENG, L. (2014). Sub-pixel change detection for urban land-cover analysis via multi-temporal remote sensing images. Geo-spatial Information Science, 17(1), pp.26–38. doi:https://doi.org/10.1080/10095020.2014.889268.\nGómez, C., White, J.C. and Wulder, M.A. (2016). Optical remotely sensed time series data for land cover classification: A review. ISPRS Journal of Photogrammetry and Remote Sensing, 116, pp.55–72. doi:https://doi.org/10.1016/j.isprsjprs.2016.03.008."
  },
  {
    "objectID": "week9.html#week-6-an-introduction-to-google-earth-engine",
    "href": "week9.html#week-6-an-introduction-to-google-earth-engine",
    "title": "9  Week9",
    "section": "9.1 Week 6: An introduction to Google Earth Engine",
    "text": "9.1 Week 6: An introduction to Google Earth Engine\n\n9.1.1 Summary:\nThis is a mind map of this week’s lecture.\n\nknitr::include_graphics(\"figures/w6-GEE.png\")\n\n\n\n\nThrough this week’s practical content, I initially learned how to use JavaScript to write code in GEE, including the use of some basic programming concepts such as variables, strings, lists, and dictionaries. First, geographical information points were created, Landsat data was imported, and GEE operations such as image clipping and texture measurement were performed. I also learned to process data and how to load, filter and display image datasets, by processing image collections, using equal methods such as straight, mean, etc. to synthesize images. Next, I learned how to use principal component analysis (PCA) to reduce the dimensionality of image data, including how to calculate covariance matrices, eigenvalues, and eigenvectors, and output the results as images.\n\n\n9.1.2 Applications:\nGoogle Earth Engine (GEE) is widely used in many fields because of its powerful data analysis capabilities and large geographical information data sets. Some major applications include: environmental monitoring, agriculture, climate change research, land cover mapping, disaster management, etc.\nAmong them, in agriculture, GEE can be used to monitor crops, predict yields, and manage agricultural resources more effectively. It helps assess crop health, soil moisture, and predict pest infestations. Mutanga and Kumar (2019) studied several key applications of GEE in agriculture, including crop yield estimation, crop area mapping, pest and disease vulnerability and suitability assessment. Among them, using Terra MODIS data and Landsat data, GEE was able to estimate the total primary productivity of seven crops in Montana, USA, from 2008 to 2015 at a spatial resolution of 30 meters. High spatial resolution Worldview 2 data were used to map smallholder heterogeneous farmland areas in the African context of Mali. This mapping utilizes set rules to optimize classification accuracy, demonstrating the high processing power of GEE. Moreover, using a combination of 10-day period Sentinel data and 16-day period Landsat TM data, a map of farmland and non-farmland area across the African continent was drawn. And classify the above data using random forest algorithm and recursive hierarchical partitioning to further analyze and understand the data.\nThere is also a study on Canadian cropping intensity (ACI) mapping using Google Earth Engine (GEE). Amani et al. (2020) proposed a cloud computing method using a combination of multi-date Sentinel-1 and Sentinel-2 images acquired in 2018, implemented on the GEE platform, to generate object-based ACI maps. By applying artificial neural networks (ANN), 17 farmland categories in 10 Canadian provinces were delineated. The research results show that the overall classification accuracy is 77%, and the average producer accuracy (PA) and user accuracy (UA) of the cultivated land category are 79% and 77% respectively. It also proves that using the GEE cloud platform and open-access Sentinel-1/-2 satellite images greatly reduces time and economic costs compared to using local computing resources and expensive RADARSAT-2 images, helping to automate future ACI maps. Production.\nThese two studies demonstrate the application of Google Earth Engine (GEE) in the agricultural field, especially the potential in crop monitoring, yield prediction, and resource management. Although their geographical areas of focus and specific applications are different, they collectively reflect GEE’s ability to process large amounts of geospatial data and perform efficient classification and analysis. Both studies used satellite data, including Sentinel-1, Sentinel-2 and Landsat data, for map production and analysis. And both aim to improve agricultural management and monitoring through more precise geospatial data analysis, such as crop yield estimation, farmland classification, etc. However, the first study focused more on the estimation of total primary productivity of crops, mapping of farmland area and classification of small-scale farmland using high-resolution data using methods such as ensemble rules and random forest algorithms. The second study focuses on using artificial neural network (ANN) technology to generate object-based crop intensity (ACI) maps on the GEE platform. Through these studies, we can see the broad applicability and benefits of GEE in agricultural research in different regions around the world.\n\n\n9.1.3 Reflection:\nThe Google Earth Engine (GEE) we learned this week is inspiring, and it vividly demonstrates the combination of programming and geospatial analysis. When I first tried programming in GEE using JavaScript, I found it difficult but took it as a challenge. Through these, I realized the importance of independent learning and problem solving. When encountering programming difficulties, although the code in the tutorial is very detailed, when trying to fully understand it, I learned how to search for relevant information, read documents, and ask peers for help. These abilities will be extremely valuable for my future study and work. of.\n\n\n9.1.4 References:\nAmani, M., Kakooei, M., Moghimi, A., Ghorbanian, A., Ranjgar, B., Mahdavi, S., Davidson, A., Fisette, T., Rollin, P., Brisco, B. and Mohammadzadeh, A. (2020). Application of Google Earth Engine Cloud Computing Platform, Sentinel Imagery, and Neural Networks for Crop Mapping in Canada. Remote Sensing, 12(21), p.3561. doi:https://doi.org/10.3390/rs12213561.\nAmani, M., Kakooei, M., Moghimi, A., Ghorbanian, A., Ranjgar, B., Mahdavi, S., Davidson, A., Fisette, T., Rollin, P., Brisco, B. and Mohammadzadeh, A. (2020). Application of Google Earth Engine Cloud Computing Platform, Sentinel Imagery, and Neural Networks for Crop Mapping in Canada. Remote Sensing, 12(21), p.3561. doi:https://doi.org/10.3390/rs12213561."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "learningdiary",
    "section": "",
    "text": "Preface\nadd more in the future\n\n1 + 1\n\n[1] 2"
  }
]